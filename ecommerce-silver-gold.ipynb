{"metadata":{"kernelspec":{"name":"glue_pyspark","display_name":"Glue PySpark","language":"python"},"language_info":{"name":"Python_Glue_Session","mimetype":"text/x-python","codemirror_mode":{"name":"python","version":3},"pygments_lexer":"python3","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%idle_timeout 2880\n%glue_version 4.0\n%worker_type G.1X\n%number_of_workers 2\n\nimport sys\nfrom awsglue.dynamicframe import DynamicFrame\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\nimport pyspark.pandas as pd\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import col, lpad, to_timestamp, when, datediff, to_date, count, sum, expr, first, mean, avg\n\nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)","metadata":{"trusted":true,"tags":[]},"execution_count":87,"outputs":[{"name":"stderr","text":"You are already connected to a glueetl session 0b3af2dd-84cf-4717-894b-df2f37519480.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n","output_type":"stream"},{"name":"stdout","text":"Current idle_timeout is 2880 minutes.\nidle_timeout has been set to 2880 minutes.\n","output_type":"stream"},{"name":"stderr","text":"You are already connected to a glueetl session 0b3af2dd-84cf-4717-894b-df2f37519480.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n","output_type":"stream"},{"name":"stdout","text":"Setting Glue version to: 4.0\n","output_type":"stream"},{"name":"stderr","text":"You are already connected to a glueetl session 0b3af2dd-84cf-4717-894b-df2f37519480.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n","output_type":"stream"},{"name":"stdout","text":"Previous worker type: G.1X\nSetting new worker type to: G.1X\n","output_type":"stream"},{"name":"stderr","text":"You are already connected to a glueetl session 0b3af2dd-84cf-4717-894b-df2f37519480.\n\nNo change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n","output_type":"stream"},{"name":"stdout","text":"Previous number of workers: 2\nSetting new number of workers to: 2\n\n","output_type":"stream"}]},{"cell_type":"code","source":"silver_orders = glueContext.create_dynamic_frame.from_catalog(database='ecommerce-datalake', table_name='orders').toDF()\nsilver_order_items = glueContext.create_dynamic_frame.from_catalog(database='ecommerce-datalake', table_name='orders_items').toDF()\nsilver_order_reviews = glueContext.create_dynamic_frame.from_catalog(database='ecommerce-datalake', table_name='orders_reviews').toDF()\nsilver_order_payments = glueContext.create_dynamic_frame.from_catalog(database='ecommerce-datalake', table_name='orders_payments').toDF()\nsilver_product = glueContext.create_dynamic_frame.from_catalog(database='ecommerce-datalake', table_name='product').toDF()\nsilver_customers = glueContext.create_dynamic_frame.from_catalog(database='ecommerce-datalake', table_name='customers').toDF()\nsilver_seller = glueContext.create_dynamic_frame.from_catalog(database='ecommerce-datalake', table_name='sellers')","metadata":{"trusted":true,"tags":[]},"execution_count":88,"outputs":[{"name":"stdout","text":"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# 1. Update order_status based on conditions\nsilver_orders = silver_orders.withColumn(\n    'order_status',\n    when(col('order_status').isin(['invoiced', 'shipped', 'processing', 'created', 'approved']), 'in-progress')\n    .when(col('order_delivered_customer_date').isNotNull(), 'delivered')\n    .otherwise(col('order_status'))\n)\n\n# 2. Drop columns\nsilver_orders = silver_orders.drop('order_approved_at', 'order_delivered_carrier_date')\n\n# 3. Calculate estimated_days_to_delivery and actual_delivery_in_days\nsilver_orders = silver_orders.withColumn(\n    'estimated_days_to_delivery',\n    datediff(col('order_estimated_delivery_date'), col('order_purchase_timestamp'))\n)\nsilver_orders = silver_orders.withColumn(\n    'actual_delivery_in_days',\n    datediff(col('order_delivered_customer_date'), col('order_purchase_timestamp'))\n)\n\n# 4. Convert timestamps to date\nsilver_orders = silver_orders.withColumn(\n    'order_purchase_timestamp', to_date(col('order_purchase_timestamp'))\n)\nsilver_orders = silver_orders.withColumn(\n    'order_delivered_customer_date', to_date(col('order_delivered_customer_date'))\n)\nsilver_orders = silver_orders.withColumn(\n    'order_estimated_delivery_date', to_date(col('order_estimated_delivery_date'))\n)","metadata":{"trusted":true,"tags":[]},"execution_count":89,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"#Cleanup order_items tables\nsilver_order_items = silver_order_items.dropDuplicates()\n\n# Drop the 'shipping_limit_date' column\nsilver_order_items = silver_order_items.drop('shipping_limit_date')\n","metadata":{"trusted":true,"tags":[]},"execution_count":90,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"#####cleanup order_payments\n# Group by 'order_id' and aggregate\ngrouped = silver_order_payments.groupBy('order_id')\n\n# Count the number of occurrences of 'order_id'\ncount_values = grouped.agg(count('order_id').alias('count_values'))\n\n# Calculate the mode of 'payment_type'\nmode_status = grouped.agg(expr('first(payment_type)').alias('payment_type'))\n\n# Sum the 'payment_value'\nsum_amount = grouped.agg(sum('payment_value').alias('total_amount'))\n\n# Combine the results\nsilver_order_payments_aggregate = count_values.join(mode_status, on='order_id').join(sum_amount, on='order_id')\n","metadata":{"trusted":true,"tags":[]},"execution_count":91,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"####create fact table\n# 1. Merge DataFrames\norders_fact = silver_orders.join(silver_order_items, on='order_id', how='left')\norders_fact = orders_fact.join(silver_order_payments_aggregate, on='order_id', how='left')\n\n# 2. Update column values based on conditions\norders_fact = orders_fact.withColumn(\n    'order_status',\n    when((col('order_status') == 'in-progress') & col('product_id').isNull(), 'unavailable')\n    .otherwise(col('order_status'))\n)\n\n# 3. Drop columns\norders_fact = orders_fact.drop('order_item_id', 'count_values')\n\n# 4. Rename columns\norders_fact = orders_fact.withColumnRenamed('seller_zip_code_prefix', 'seller_zip_code') \\\n    .withColumnRenamed('order_purchase_timestamp', 'order_purchase_date') \\\n    .withColumnRenamed('order_delivered_customer_date', 'order_delivered_date') \\\n    .withColumnRenamed('order_estimated_delivery_date', 'order_estimated_delivery_date') \\\n    .withColumnRenamed('total_amount', 'total_amount_per_order_id')\n\nspark_orders_fact = DynamicFrame.fromDF(orders_fact, glueContext) ","metadata":{"trusted":true,"tags":[]},"execution_count":92,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"datasink1 = glueContext.write_dynamic_frame.from_options(frame = spark_orders_fact, connection_type = \"s3\", connection_options = {\"path\": \"s3://ecommerce-gold/fact_order/\"}, format = \"parquet\")\n","metadata":{"trusted":true,"tags":[]},"execution_count":93,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert 'review_creation_date' to date format\nsilver_order_reviews = silver_order_reviews.withColumn(\n    'review_creation_date',\n    to_date(col('review_creation_date').cast('date'))\n)\nspark_silver_order_reviews = DynamicFrame.fromDF(silver_order_reviews, glueContext) ","metadata":{"trusted":true,"tags":[]},"execution_count":94,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"datasink2 = glueContext.write_dynamic_frame.from_options(frame = spark_silver_order_reviews, connection_type = \"s3\", connection_options = {\"path\": \"s3://ecommerce-gold/dim_order_review/\"}, format = \"parquet\")\n","metadata":{"trusted":true,"tags":[]},"execution_count":95,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Drop column 'customer_unique_id'\nsilver_customers = silver_customers.drop('customer_unique_id')\n\n# Drop rows with null values in specified columns\nrequired_columns = ['customer_id', 'customer_zip_code', 'customer_city', 'customer_state']\nsilver_customers = silver_customers.na.drop(subset=required_columns)\nspark_silver_customers = DynamicFrame.fromDF(silver_customers, glueContext) ","metadata":{"trusted":true,"tags":[]},"execution_count":96,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"datasink3 = glueContext.write_dynamic_frame.from_options(frame = spark_silver_customers, connection_type = \"s3\", connection_options = {\"path\": \"s3://ecommerce-gold/dim_customers/\"}, format = \"parquet\")\n","metadata":{"trusted":true,"tags":[]},"execution_count":97,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"silver_product_df = silver_product.toPandas()\nsilver_product_df = silver_product_df.drop(['product_category_name','product_name_lenght','product_description_lenght','product_photos_qty'],axis=1)\nsilver_product_df[\"product_weight_g\"] = silver_product_df['product_weight_g'].fillna(silver_product_df.groupby('product_category_name_english')['product_weight_g'].transform('mean'))\nsilver_product_df[\"product_length_cm\"] = silver_product_df['product_length_cm'].fillna(silver_product_df.groupby('product_category_name_english')['product_length_cm'].transform('mean'))\nsilver_product_df[\"product_height_cm\"] = silver_product_df['product_height_cm'].fillna(silver_product_df.groupby('product_category_name_english')['product_height_cm'].transform('mean'))\nsilver_product_df[\"product_width_cm\"] = silver_product_df['product_width_cm'].fillna(silver_product_df.groupby('product_category_name_english')['product_width_cm'].transform('mean'))\nsilver_product_df = silver_product_df.rename({\"product_category_name_english\":\"product_category\"},axis=1)\nsilver_product = spark.createDataFrame(silver_product_df)\nsilver_product = DynamicFrame.fromDF(silver_product, glueContext) ","metadata":{"trusted":true,"tags":[]},"execution_count":98,"outputs":[{"name":"stdout","text":"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for column, series in pdf.iteritems():\n/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  for column, series in pdf.iteritems():\n","output_type":"stream"}]},{"cell_type":"code","source":"datasink4 = glueContext.write_dynamic_frame.from_options(frame = silver_product, connection_type = \"s3\", connection_options = {\"path\": \"s3://ecommerce-gold/dim_product/\"}, format = \"parquet\")\n","metadata":{"trusted":true,"tags":[]},"execution_count":99,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"datasink5 = glueContext.write_dynamic_frame.from_options(frame = silver_seller, connection_type = \"s3\", connection_options = {\"path\": \"s3://ecommerce-gold/dim_seller/\"}, format = \"parquet\")\n","metadata":{"trusted":true,"tags":[]},"execution_count":100,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}